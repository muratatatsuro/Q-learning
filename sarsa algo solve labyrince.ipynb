{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"価値反復法\\u3000報酬Rt t:各ステップ\\u3000\\n   報酬和Gt=Rt+1+Rt+2... 未来に得られる報酬\\n   これらは割引して捉える\\u3000\\n   γ:割引率\\n   Gt=Rt+1+γRt+2+γ**2*Rt+3+...\\n   \\n   \\n   価値概念：行動価値、状態価値の二つ\\n   ゴールにつくとRt=1\\n   \\n   行動価値：Q\\n   state=S7,action='right=1ならばRt+1=1\\n   =>行動価値関数Q(s,a)<polocy dependence>を用いると\\n   Q(s=7,a=1)=1\\n   \\n   state=S7,action='up'=0\\n   2step分lossする\\n   Q(s=7,a=0)=γ**2*1\\n   \\n   状態価値：V\\n   state=S7=>V(s=7)=1\\n   state=S4=>V(s=4)=γ*1 or V(s=4)=Rt+1+γ*V(s=7)\\n   ただしS8以外ではRt+1=0であることに注意\\n   \\n   一般化\\n   V(s)=max(R(s,a)+γ*V(s(s,a)))\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"価値反復法　報酬Rt t:各ステップ　\n",
    "   報酬和Gt=Rt+1+Rt+2... 未来に得られる報酬\n",
    "   これらは割引して捉える　\n",
    "   γ:割引率\n",
    "   Gt=Rt+1+γRt+2+γ**2*Rt+3+...\n",
    "   \n",
    "   \n",
    "   価値概念：行動価値、状態価値の二つ\n",
    "   ゴールにつくとRt=1\n",
    "   \n",
    "   行動価値：Q\n",
    "   state=S7,action='right=1ならばRt+1=1\n",
    "   =>行動価値関数Q(s,a)<polocy dependence>を用いると\n",
    "   Q(s=7,a=1)=1\n",
    "   \n",
    "   state=S7,action='up'=0\n",
    "   2step分lossする\n",
    "   Q(s=7,a=0)=γ**2*1\n",
    "   \n",
    "   状態価値：V\n",
    "   state=S7=>V(s=7)=1\n",
    "   state=S4=>V(s=4)=γ*1 or V(s=4)=Rt+1+γ*V(s=7)\n",
    "   ただしS8以外ではRt+1=0であることに注意\n",
    "   \n",
    "   一般化\n",
    "   V(s)=max(R(s,a)+γ*V(s(s,a)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEzCAYAAABJzXq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZanpQY9BNHbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sarsa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "x=np.arange(0,4,1)\n",
    "grid=np.array([x,x])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "ax=plt.gca()\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,3)\n",
    "\n",
    "#迷路の壁を作成\n",
    "plt.plot((grid[0][1],grid[1][1]),(grid[0][1],grid[1][0]),c='red',linewidth=2)\n",
    "plt.plot((grid[0][1],grid[1][2]),(grid[0][2],grid[1][2]),c='red',linewidth=2)\n",
    "plt.plot((grid[0][2],grid[1][2]),(grid[0][2],grid[1][1]),c='red',linewidth=2)\n",
    "plt.plot((grid[0][3],grid[1][2]),(grid[0][1],grid[1][1]),c='red',linewidth=2)\n",
    "\n",
    "#迷路の状態を明示\n",
    "plt.text(0.5,0.5,'S6',size=20,ha='center')\n",
    "plt.text(0.5,1.5,'S3',size=20,ha='center')\n",
    "plt.text(0.5,2.5,'S0',size=20,ha='center')\n",
    "plt.text(0.5,2.3,'start',size=15,ha='center')\n",
    "plt.text(1.5,0.5,'S7',size=20,ha='center')\n",
    "plt.text(1.5,1.5,'S4',size=20,ha='center')\n",
    "plt.text(1.5,2.5,'S1',size=20,ha='center')\n",
    "plt.text(2.5,0.5,'S8',size=20,ha='center')\n",
    "plt.text(2.5,0.3,'goal',size=15,ha='center')\n",
    "plt.text(2.5,1.5,'S5',size=20,ha='center')\n",
    "plt.text(2.5,2.5,'S2',size=20,ha='center')\n",
    "\n",
    "#start mark\n",
    "line,=ax.plot(0.5,2.5,marker='o',color='lightblue',markersize=60)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#policy array\n",
    "theta_0=np.array([[np.nan,1,1,np.nan],\n",
    "                  [np.nan,np.nan,1,1],\n",
    "                  [np.nan,1,np.nan,1],\n",
    "                  [1,1,1,np.nan],\n",
    "                  [np.nan,1,np.nan,np.nan],\n",
    "                  [1,np.nan,np.nan,np.nan],\n",
    "                  [1,np.nan,np.nan,np.nan],\n",
    "                  [1,np.nan,1,np.nan]\n",
    "                  ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan  0.72907246  0.86863874         nan]\n",
      " [        nan         nan  0.8021949   0.44032879]\n",
      " [        nan  0.00341353         nan  0.6227598 ]\n",
      " [ 0.38884061  0.55857319  0.28816602         nan]\n",
      " [        nan  0.35915519         nan         nan]\n",
      " [ 0.83762927         nan         nan         nan]\n",
      " [ 0.99302353         nan         nan         nan]\n",
      " [ 0.1847708          nan  0.43250653         nan]]\n"
     ]
    }
   ],
   "source": [
    "#行動価値関数Q(s,a)をarray表現\n",
    "#Qの初期化\n",
    "a,b=theta_0.shape\n",
    "Q=np.random.rand(a,b)*theta_0\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action 1\n",
      "new state 3\n"
     ]
    }
   ],
   "source": [
    "#一定の確率εでランダムに行動し、1-εでQが最大になる行動を選択\n",
    "\n",
    "#policy_to_probの実装\n",
    "def policy_to_prob(theta):\n",
    "    s,t=theta.shape\n",
    "    prob_array=np.zeros([s,t])\n",
    "    \n",
    "    for i in range(s):\n",
    "        prob_array[i,:]=theta[i,:]/np.nansum(theta[i,:])\n",
    "        \n",
    "    #np.nanは行動をとれないので確率0\n",
    "    prob_array=np.nan_to_num(prob_array)\n",
    "    \n",
    "    return prob_array\n",
    "\n",
    "#greedy\n",
    "epsilon=0.3\n",
    "def eps_greedy(Q,prob_array,now_state,epsilon):\n",
    "    direction=['up','down','right','left']\n",
    "    \n",
    "    #ランダムに行動をする\n",
    "    if np.random.rand()<epsilon:\n",
    "        next_direction=np.random.choice(direction,p=prob_array[now_state,:])\n",
    "    #それ以外はQを最大にする方向の行動をとる\n",
    "    else:\n",
    "        next_direction=direction[np.nanargmax(Q[now_state,:])]\n",
    "        \n",
    "    if next_direction==direction[0]:\n",
    "        action=0\n",
    "        next_state=now_state-3\n",
    "    elif next_direction==direction[1]:\n",
    "        action=1\n",
    "        next_state=now_state+3\n",
    "    elif next_direction==direction[2]:\n",
    "        action=2\n",
    "        next_state=now_state+1\n",
    "    elif next_direction==direction[3]:\n",
    "        action=3\n",
    "        next_state=now_state-1\n",
    "        \n",
    "    return [action,next_state]\n",
    "\n",
    "prob_array=policy_to_prob(theta_0)\n",
    "now_state=0\n",
    "[action,new_state]=eps_greedy(theta_0,prob_array,now_state,epsilon=0.3)\n",
    "print('action',action)\n",
    "print('new state',new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan  0.03095243  0.18606583         nan]\n",
      " [        nan         nan  0.65554367  0.02934499]\n",
      " [        nan  0.46258361         nan  0.89900432]\n",
      " [ 0.84707658  0.01515099  0.21922183         nan]\n",
      " [        nan  0.77824764         nan         nan]\n",
      " [ 0.64273377         nan         nan         nan]\n",
      " [ 0.3224585          nan         nan         nan]\n",
      " [ 0.4845942          nan  0.79979357         nan]]\n",
      "[[        nan  0.04539493  0.18606583         nan]\n",
      " [        nan         nan  0.65554367  0.02934499]\n",
      " [        nan  0.46258361         nan  0.89900432]\n",
      " [ 0.84707658  0.01515099  0.21922183         nan]\n",
      " [        nan  0.77824764         nan         nan]\n",
      " [ 0.64273377         nan         nan         nan]\n",
      " [ 0.3224585          nan         nan         nan]\n",
      " [ 0.4845942          nan  0.79979357         nan]]\n",
      "[ 0.18606583  0.65554367  0.89900432  0.84707658  0.77824764  0.64273377\n",
      "  0.3224585   0.79979357]\n"
     ]
    }
   ],
   "source": [
    "#勾配方策方がsarsaアルゴリズムに変換\n",
    "lr=0.1\n",
    "a,b=theta_0.shape\n",
    "#行動価値関数\n",
    "Q=np.random.rand(a,b)*theta_0\n",
    "#状態価値関数\n",
    "V=np.nanmax(Q,axis=1)\n",
    "\n",
    "Q_old=Q.copy()\n",
    "\n",
    "now_state=0\n",
    "r=0\n",
    "gamma=0.8\n",
    "prob_array=policy_to_prob(theta_0)\n",
    "[action,new_state]=eps_greedy(theta_0,prob_array,now_state,epsilon=0.3)\n",
    "action_next=2\n",
    "\n",
    "if new_state==8:\n",
    "    Q[now_state,action]=Q[now_state,action]+lr*(r-Q[now_state,action])\n",
    "else:\n",
    "    Q[now_state,action]=Q[now_state,action]+lr*(r+gamma*Q[new_state,action_next]-Q[now_state,action])\n",
    "\n",
    "new_V=np.nanmax(Q,axis=1)\n",
    "print(Q_old)\n",
    "print(Q)\n",
    "print(new_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarsa algorithmを関数化\n",
    "def Sarsa(now_state,now_action,next_state,next_action,Q,lr,r,gamma):\n",
    "    if next_state==8:\n",
    "        Q[now_state,now_action]=Q[now_state,now_action]+lr*(r-Q[now_state,now_action])\n",
    "    else:\n",
    "        Q[now_state,now_action]=Q[now_state,now_action]+lr*(r+gamma*Q[next_state,next_action]-Q[now_state,now_action])\n",
    "        \n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#goal関数\n",
    "def get_goal(Q,epsilon,lr,gamma,prob_array):\n",
    "    now_state=0\n",
    "    s_a_history=[[now_state,np.nan]]\n",
    "    \n",
    "    while True:\n",
    "        [now_action,next_state]=eps_greedy(Q,prob_array,now_state,epsilon)\n",
    "        s_a_history[-1][1]=now_action\n",
    "        \n",
    "        s_a_history.append([next_state,np.nan])\n",
    "        \n",
    "        if next_state==8:\n",
    "            #goalをしたら報酬をもらえて次が動けなくなる\n",
    "            r=1\n",
    "            next_action=np.nan\n",
    "        else:\n",
    "            r=0\n",
    "            [next_action,_]=eps_greedy(Q,prob_array,next_state,epsilon)\n",
    "            \n",
    "        #価値関数を更新\n",
    "        Q=Sarsa(now_state,now_action,next_state,next_action,Q,lr,r,gamma)\n",
    "        \n",
    "        #終了判定\n",
    "        if next_state==8:\n",
    "            break\n",
    "        else:\n",
    "            now_state=next_state\n",
    "            \n",
    "    return [s_a_history,Q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 step\n",
      "1.19235522381\n",
      "labyrince is solved 64 times required\n",
      "2 step\n",
      "0.283468215643\n",
      "labyrince is solved 40 times required\n",
      "3 step\n",
      "0.227387547205\n",
      "labyrince is solved 34 times required\n",
      "4 step\n",
      "0.422669478019\n",
      "labyrince is solved 130 times required\n",
      "5 step\n",
      "0.0879711727578\n",
      "labyrince is solved 44 times required\n",
      "6 step\n",
      "0.0489300765045\n",
      "labyrince is solved 4 times required\n",
      "7 step\n",
      "0.0425006917322\n",
      "labyrince is solved 4 times required\n",
      "8 step\n",
      "0.0369390307694\n",
      "labyrince is solved 4 times required\n",
      "9 step\n",
      "0.032375424952\n",
      "labyrince is solved 4 times required\n",
      "10 step\n",
      "0.0293213631409\n",
      "labyrince is solved 4 times required\n",
      "11 step\n",
      "0.0271169179751\n",
      "labyrince is solved 4 times required\n",
      "12 step\n",
      "0.0250717058602\n",
      "labyrince is solved 4 times required\n",
      "13 step\n",
      "0.0233706491665\n",
      "labyrince is solved 4 times required\n",
      "14 step\n",
      "0.0218313202785\n",
      "labyrince is solved 4 times required\n",
      "15 step\n",
      "0.0204363242637\n",
      "labyrince is solved 4 times required\n",
      "16 step\n",
      "0.0191698175508\n",
      "labyrince is solved 4 times required\n",
      "17 step\n",
      "0.018017454275\n",
      "labyrince is solved 4 times required\n",
      "18 step\n",
      "0.0169663144115\n",
      "labyrince is solved 4 times required\n",
      "19 step\n",
      "0.0160048197336\n",
      "labyrince is solved 4 times required\n",
      "20 step\n",
      "0.0151226423717\n",
      "labyrince is solved 4 times required\n",
      "21 step\n",
      "0.0143106097072\n",
      "labyrince is solved 4 times required\n",
      "22 step\n",
      "0.0135606084771\n",
      "labyrince is solved 4 times required\n",
      "23 step\n",
      "0.0128654902693\n",
      "labyrince is solved 4 times required\n",
      "24 step\n",
      "0.0122189800168\n",
      "labyrince is solved 4 times required\n",
      "25 step\n",
      "0.0116155886421\n",
      "labyrince is solved 4 times required\n",
      "26 step\n",
      "0.0110505306333\n",
      "labyrince is solved 4 times required\n",
      "27 step\n",
      "0.0105196470426\n",
      "labyrince is solved 4 times required\n",
      "28 step\n",
      "0.010019334167\n",
      "labyrince is solved 4 times required\n",
      "29 step\n",
      "0.00954647799247\n",
      "labyrince is solved 4 times required\n",
      "30 step\n",
      "0.00909839434929\n",
      "labyrince is solved 4 times required\n",
      "31 step\n",
      "0.00867277462022\n",
      "labyrince is solved 4 times required\n",
      "32 step\n",
      "0.00826763677434\n",
      "labyrince is solved 4 times required\n",
      "33 step\n",
      "0.00788128144503\n",
      "labyrince is solved 4 times required\n",
      "34 step\n",
      "0.0075122527388\n",
      "labyrince is solved 4 times required\n",
      "35 step\n",
      "0.00715930344248\n",
      "labyrince is solved 4 times required\n",
      "36 step\n",
      "0.00682136428844\n",
      "labyrince is solved 4 times required\n",
      "37 step\n",
      "0.00649751693818\n",
      "labyrince is solved 4 times required\n",
      "38 step\n",
      "0.00618697035196\n",
      "labyrince is solved 4 times required\n",
      "39 step\n",
      "0.00588904022401\n",
      "labyrince is solved 4 times required\n",
      "40 step\n",
      "0.00560313117797\n",
      "labyrince is solved 4 times required\n",
      "41 step\n",
      "0.0053287214352\n",
      "labyrince is solved 4 times required\n",
      "42 step\n",
      "0.00506534968706\n",
      "labyrince is solved 4 times required\n",
      "43 step\n",
      "0.00481260392234\n",
      "labyrince is solved 4 times required\n",
      "44 step\n",
      "0.00457011198049\n",
      "labyrince is solved 4 times required\n",
      "45 step\n",
      "0.00433753362103\n",
      "labyrince is solved 4 times required\n",
      "46 step\n",
      "0.00411455391838\n",
      "labyrince is solved 4 times required\n",
      "47 step\n",
      "0.00390087780963\n",
      "labyrince is solved 4 times required\n",
      "48 step\n",
      "0.00369622563985\n",
      "labyrince is solved 4 times required\n",
      "49 step\n",
      "0.00350032956593\n",
      "labyrince is solved 4 times required\n",
      "50 step\n",
      "0.00331293069467\n",
      "labyrince is solved 4 times required\n",
      "51 step\n",
      "0.00313377684532\n",
      "labyrince is solved 4 times required\n",
      "52 step\n",
      "0.00296262083899\n",
      "labyrince is solved 4 times required\n",
      "53 step\n",
      "0.00279921922958\n",
      "labyrince is solved 4 times required\n",
      "54 step\n",
      "0.00264333140116\n",
      "labyrince is solved 4 times required\n",
      "55 step\n",
      "0.00249471896669\n",
      "labyrince is solved 4 times required\n",
      "56 step\n",
      "0.00235314541146\n",
      "labyrince is solved 4 times required\n",
      "57 step\n",
      "0.00221837593238\n",
      "labyrince is solved 4 times required\n",
      "58 step\n",
      "0.00209017743146\n",
      "labyrince is solved 4 times required\n",
      "59 step\n",
      "0.00196831862764\n",
      "labyrince is solved 4 times required\n",
      "60 step\n",
      "0.00185257025699\n",
      "labyrince is solved 4 times required\n",
      "61 step\n",
      "0.00174270533571\n",
      "labyrince is solved 4 times required\n",
      "62 step\n",
      "0.00163849946503\n",
      "labyrince is solved 4 times required\n",
      "63 step\n",
      "0.00153973116033\n",
      "labyrince is solved 4 times required\n",
      "64 step\n",
      "0.00144618219046\n",
      "labyrince is solved 4 times required\n",
      "65 step\n",
      "0.00135763791572\n",
      "labyrince is solved 4 times required\n",
      "66 step\n",
      "0.00127388761549\n",
      "labyrince is solved 4 times required\n",
      "67 step\n",
      "0.00119472479844\n",
      "labyrince is solved 4 times required\n",
      "68 step\n",
      "0.00111994749017\n",
      "labyrince is solved 4 times required\n",
      "69 step\n",
      "0.00104935849448\n",
      "labyrince is solved 4 times required\n",
      "70 step\n",
      "0.000982765625617\n",
      "labyrince is solved 4 times required\n",
      "71 step\n",
      "0.000919981910133\n",
      "labyrince is solved 4 times required\n",
      "72 step\n",
      "0.000860825757582\n",
      "labyrince is solved 4 times required\n",
      "73 step\n",
      "0.000805121100117\n",
      "labyrince is solved 4 times required\n",
      "74 step\n",
      "0.000752697501557\n",
      "labyrince is solved 4 times required\n",
      "75 step\n",
      "0.000703390236905\n",
      "labyrince is solved 4 times required\n",
      "76 step\n",
      "0.000657040343684\n",
      "labyrince is solved 4 times required\n",
      "77 step\n",
      "0.000613494646656\n",
      "labyrince is solved 4 times required\n",
      "78 step\n",
      "0.000572605757702\n",
      "labyrince is solved 4 times required\n",
      "79 step\n",
      "0.000534232052728\n",
      "labyrince is solved 4 times required\n",
      "80 step\n",
      "0.000498237627548\n",
      "labyrince is solved 4 times required\n",
      "81 step\n",
      "0.0004644922347\n",
      "labyrince is solved 4 times required\n",
      "82 step\n",
      "0.000432871203165\n",
      "labyrince is solved 4 times required\n",
      "83 step\n",
      "0.000403255342888\n",
      "labyrince is solved 4 times required\n",
      "84 step\n",
      "0.000375530835964\n",
      "labyrince is solved 4 times required\n",
      "85 step\n",
      "0.000349589116278\n",
      "labyrince is solved 4 times required\n",
      "86 step\n",
      "0.000325326739282\n",
      "labyrince is solved 4 times required\n",
      "87 step\n",
      "0.000302645243503\n",
      "labyrince is solved 4 times required\n",
      "88 step\n",
      "0.000281451005294\n",
      "labyrince is solved 4 times required\n",
      "89 step\n",
      "0.000261655088189\n",
      "labyrince is solved 4 times required\n",
      "90 step\n",
      "0.000243173088164\n",
      "labyrince is solved 4 times required\n",
      "91 step\n",
      "0.000225924975965\n",
      "labyrince is solved 4 times required\n",
      "92 step\n",
      "0.000209834937585\n",
      "labyrince is solved 4 times required\n",
      "93 step\n",
      "0.00019483121384\n",
      "labyrince is solved 4 times required\n",
      "94 step\n",
      "0.000180845939931\n",
      "labyrince is solved 4 times required\n",
      "95 step\n",
      "0.000167814985757\n",
      "labyrince is solved 4 times required\n",
      "96 step\n",
      "0.000155677797667\n",
      "labyrince is solved 4 times required\n",
      "97 step\n",
      "0.000144377242262\n",
      "labyrince is solved 4 times required\n",
      "98 step\n",
      "0.000133859452759\n",
      "labyrince is solved 4 times required\n",
      "99 step\n",
      "0.000124073678383\n",
      "labyrince is solved 4 times required\n",
      "100 step\n",
      "0.000114972137153\n",
      "labyrince is solved 4 times required\n"
     ]
    }
   ],
   "source": [
    "#迷路を解く\n",
    "prob_array=policy_to_prob(theta_0)\n",
    "a,b=theta_0.shape\n",
    "#行動価値関数初期化\n",
    "Q=np.random.rand(a,b)*theta_0\n",
    "#状態価値関数初期化\n",
    "V=np.nanmax(Q,axis=1)\n",
    "epsilon=0.5#ランダム確率\n",
    "lr=0.1#学習率\n",
    "gamma=0.9#ステップ割引率\n",
    "\n",
    "is_continue=True#学習を続けるかを判定\n",
    "step=1\n",
    "\n",
    "while is_continue:\n",
    "    print('%d step'%step)\n",
    "    \n",
    "    epsilon=epsilon/2\n",
    "    [s_a_history,Q]=get_goal(Q,epsilon,lr,gamma,prob_array)\n",
    "    \n",
    "    new_V=np.nanmax(Q,axis=1)\n",
    "    error=np.sum(np.abs(new_V-V))\n",
    "    print(error)\n",
    "    \n",
    "    V=new_V\n",
    "    \n",
    "    print('labyrince is solved %d times required'%(len(s_a_history)-1))\n",
    "    \n",
    "    step+=1\n",
    "    #stepが100を超えたらloopを抜ける\n",
    "    #もしくはerrorがある値より小さくなったら終了としても良い\n",
    "    if step>100:\n",
    "        break\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
